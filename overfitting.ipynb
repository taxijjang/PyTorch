{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x284c62d6b70>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([[1,2,1],\n",
    "                             [1,3,2],\n",
    "                             [1,3,4],\n",
    "                             [1,5,5],\n",
    "                             [1,7,5],\n",
    "                             [1,2,5],\n",
    "                             [1,6,6],\n",
    "                             [1,7,7]])\n",
    "\n",
    "y_train = torch.LongTensor([2,2,2,1,1,1,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = torch.FloatTensor([[2,1,1],[3,1,2],[3,3,4]])\n",
    "y_test = torch.LongTensor([2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SMC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(3,3)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SMC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer ,x_train, y_train):\n",
    "    nb_epoch = 20\n",
    "    for epoch in range (nb_epoch+1):\n",
    "        predicion = model(x_train)\n",
    "        \n",
    "        cost = F.cross_entropy(predicion,y_train)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('Epoch {:4d}/{} Cost : {:.6f}'.format(\n",
    "        epoch,nb_epoch,cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Cost : 2.203667\n",
      "Epoch    1/20 Cost : 1.199645\n",
      "Epoch    2/20 Cost : 1.142985\n",
      "Epoch    3/20 Cost : 1.117769\n",
      "Epoch    4/20 Cost : 1.100901\n",
      "Epoch    5/20 Cost : 1.089523\n",
      "Epoch    6/20 Cost : 1.079872\n",
      "Epoch    7/20 Cost : 1.071320\n",
      "Epoch    8/20 Cost : 1.063325\n",
      "Epoch    9/20 Cost : 1.055720\n",
      "Epoch   10/20 Cost : 1.048378\n",
      "Epoch   11/20 Cost : 1.041245\n",
      "Epoch   12/20 Cost : 1.034285\n",
      "Epoch   13/20 Cost : 1.027478\n",
      "Epoch   14/20 Cost : 1.020813\n",
      "Epoch   15/20 Cost : 1.014279\n",
      "Epoch   16/20 Cost : 1.007872\n",
      "Epoch   17/20 Cost : 1.001586\n",
      "Epoch   18/20 Cost : 0.995419\n",
      "Epoch   19/20 Cost : 0.989365\n",
      "Epoch   20/20 Cost : 0.983424\n"
     ]
    }
   ],
   "source": [
    "train(model,optimizer,x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Cost : 1.386150\n",
      "Epoch    1/20 Cost : 0.370533\n",
      "Epoch    2/20 Cost : 0.211387\n",
      "Epoch    3/20 Cost : 0.153324\n",
      "Epoch    4/20 Cost : 0.121907\n",
      "Epoch    5/20 Cost : 0.101867\n",
      "Epoch    6/20 Cost : 0.087843\n",
      "Epoch    7/20 Cost : 0.077421\n",
      "Epoch    8/20 Cost : 0.069341\n",
      "Epoch    9/20 Cost : 0.062877\n",
      "Epoch   10/20 Cost : 0.057577\n",
      "Epoch   11/20 Cost : 0.053147\n",
      "Epoch   12/20 Cost : 0.049384\n",
      "Epoch   13/20 Cost : 0.046144\n",
      "Epoch   14/20 Cost : 0.043324\n",
      "Epoch   15/20 Cost : 0.040845\n",
      "Epoch   16/20 Cost : 0.038648\n",
      "Epoch   17/20 Cost : 0.036686\n",
      "Epoch   18/20 Cost : 0.034923\n",
      "Epoch   19/20 Cost : 0.033329\n",
      "Epoch   20/20 Cost : 0.031881\n"
     ]
    }
   ],
   "source": [
    "train(model,optimizer,x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting 을 줄이는 방법에는\n",
    "1. More Data ( 데이터를 많이 모을수록 실제에 가깝게 도달이 가능하다)\n",
    "2. Less features (데이터의 특징의 수를 줄이면 오버피팅을 줄일 수 있다)\n",
    "3. Regularization\n",
    "    1) Early Stopping \n",
    "    2) Reducin NetWork Size (뉴럴네트워크의 사이즈를 줄인다)\n",
    "    3) Weight Decay\n",
    "    4) Dropout\n",
    "    5) Batch Normalization\n",
    "    \n",
    "    4번과 5번이 가장 많이 쓰인다 (딥 러닝에 한하여)\n",
    "    \n",
    "훈련을 할때 Learning Rate를 너무 크게 설정하면 cost가 점점 발산하게 되고\n",
    "너무 작게 설정하면 cost의 값이 거의 줄어들지 않게 된다\n",
    "그러므로 최적의 Learning Rate를 찾아 설정 하는것이 중요하다(여러번 하면 찾을 수 있게된다)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "pytorch"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
